<!-- # Model training --> 

This chapter explains the methodology used to train the
GAN and the factor model. We first describe a
general neural network training before focusing on the GAN model.

## Training a neutral network

Training a neural network is an empirical experiment.
We used Chen et al. (2019)â€™s best-performing
hyper-parameters choices, including the number of hidden
units and number of hidden layers, while following the best
practice of neural network training, including dynamic
learning rate and regularization.

### Adam Optimizer {#adam}

As explained in the [subsection 3.3](#nn_model), back-propagation
is one critical component in the training procedure.
We used adaptive moment estimation (Adam) proposed by
@kingma_adam_2015, which combines momentum optimization and
RMSProp, another optimizer popular before Adam. We define
$\mathbf{\theta}$ as the multi-variable weights,
$\nabla_{\mathbf{\theta}}L(\mathbf{\theta})$ as the
multi-variable gradient with respect to a loss function $L(\cdot)$,
$\eta$ as the learning rate,
$\mathbf{m}$ as the momentum vector, and $\mathbf{s}$ as the
squared of momentum vector,
$\beta_1$ as the momentum rate,
$\beta_2$ as the decay rate,
$\epsilon$ as the smoothing parameter to avoid zero
division,
$\otimes$ as the element wise multiplication,
and $\oslash$ as the element wise division.
In contrast to a gradient descent algorithm where the
updating rule is independent of the previous gradients:
$\mathbf{\theta} \leftarrow \mathbf{\theta} - \eta
\nabla_{\mathbf{\theta}} L(\mathbf{\theta})$,
a general momentum algorithm includes an additional parameter
$\mathbf{m}$ that captures the value of previous gradients,
allowing for faster convergence.
Adaptive gradient methods scale down the gradient by the
past gradient value $\sqrt{\mathbf{s}}$, decaying the steeper
gradients more than the smoother gradients, allowing the
parameter to convergence even faster.
Adam combined the momentum and adaptive gradients
techniques.

A momentum algorithm is described as:

1. $\mathbf{m} \leftarrow \beta_1 \mathbf{m} - \eta
   \nabla_{\mathbf{\theta}}L(\mathbf{\theta})$
2. $\mathbf{\theta}\leftarrow \mathbf{\theta} + \mathbf{m}$

An adaptive gradient algorithm is described as:

1. $\mathbf{s} \leftarrow \beta_2 \mathbf{s} + (1-\beta_2)
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta}) \otimes
   \nabla_{\mathbf{\theta}}L(\mathbf{\theta})$
2. $\mathbf{\theta} \leftarrow \mathbf{\theta} - \eta
   \nabla_{\mathbf{\theta}}L(\mathbf{\theta})
   \oslash \sqrt{\mathbf{s} + \epsilon}$

The Adam algorithm is described as:

1. $\mathbf{m} \leftarrow \beta_1 \mathbf{m} - (1-\beta_1)
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta})$
2. $\mathbf{s} \leftarrow \beta_2 \mathbf{s} + (1-\beta_2)
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta}) \otimes
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta})$
3. $\hat{ \mathbf{m} } \leftarrow \frac{\mathbf{m}}{1-\beta_1^t}$
4. $\hat{ \mathbf{s} } \leftarrow \frac{\mathbf{s}}{1-\beta_2^t}$
5. $\mathbf{\theta} \leftarrow \mathbf{\theta} + 
   \eta \hat{ \mathbf{m} } \oslash \sqrt{\hat{ \mathbf{s} } + \epsilon}$

### Dynamic learning rate with learning schedule

The learning rate $\eta$ affects the extent to which gradients are
updated by changing the step size in the gradient
descent method. A too high learning rate prevents gradient descent
from converging while a too low learning rate significantly
increases the training time. Instead of using a fixed
learning rate, this paper adopts exponential scheduling
where the learning rate is updated as the training epochs
$t$ increase. We denote $\eta_0$ as the initial learning
rate, $s$ as a hyper-parameter step that decreases the
impact of the initial $s$ training epochs. As a result, the
learning rate decreases faster as the training epochs
increase

$$
\eta(t) = \eta_0 0.1 ^{t/s}.
$$

### Regularization

Regularization refers to techniques used to prevent
over-fitting. Over-fitting occurs when the model is tuned
solely on the training data and does not generalise well in
unseen test data. For example, LASSO and Ridge modify
least square regression by including $\ell 1$ and $\ell 2$
penalties. Deep learning provides additional regularization
techniques, including the dropout and early stopping
adopted in this paper.

#### Regularization with dropout

Dropout is a simple yet powerful algorithm, users set a
hyper-parameter dropout rate $p$, and during training, $p$%
of the hidden units will not be included in the gradient
calculation. Intuitively, dropout forces the neural network
to train a new but dependent model during each training
epoch, avoiding relying on the same information each time.
Dropout is not used during prediction.

#### Regularization with early stopping

Early stopping is a technique that stops model training
before the model over-fits the training data. Stopping
criteria is pre-set by the users, and for a standard neural
network, the decrease in loss function is often used as the
criteria. For example, training stops if the decrease in loss between $t$
and $t+1$ is less than $\epsilon$. However, it is
harder to decide on stopping criteria for GAN models, and
this paper uses the Sharpe ratio as the stopping criteria.

## GAN architecture {#gan_structure}

```{r child="training_GAN.Rmd"}
```

## Training the factor model

The factor model can be trained using least squares
estimation. This paper uses ordinary least squares method
for estimation.
