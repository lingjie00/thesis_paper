<!-- # Model training --> 

This chapter explained the techniques we used to train the
GAN and Fama-French factor models. We first describe a
general neural network training before focusing on GAN model.

## Training neutral network

Training neural network is an empirical experiment.
We used Chen et al. (2019)â€™s best-performing
hyper-parameters tuning, including the number of hidden
units and number of hidden layers, while following the best
practice of neural network training, including dynamic
learning rate and regularisation.

### Adam Optimizer {#adam}

As explained in the [neural network model](#nn_model), back-propagation
is one critical component in the training procedure.
We used adaptive moment estimation (Adam)
[@kingma_adam_2015], which combines momentum optimization and
RMSProp, another optimizer famou before Adam. We define
$\mathbf{\theta}$ as the multi-variable weights,
$\nabla_{\mathbf{\theta}}L(\mathbf{\theta})$ as the
multi-variable gradient with respect to a loss function $L(\cdot)$,
$\eta$ as the learning rate,
$\mathbf{m}$ as the momentum vector, and $\mathbf{s}$ as the
squared of momentum vector,
$\beta_1$ as the momentum rate,
$\beta_2$ as the decay rate,
$\epsilon$ as the smoothing parameter to avoid zero
division,
$\otimes$ as the element wise multiplication,
and $\oslash$ as the element wise division.
In contrast to a gradient descent algorithm where the
updating rule is independent of the previous gradients:
$\mathbf{\theta} \leftarrow \mathbf{\theta} - \eta
\nabla_{\mathbf{\theta}} L(\mathbf{\theta})$,
a general momentum algorithm includes an additional parameter
$\mathbf{m}$ that captures the value of previous gradients,
allowing for faster convergence.
Adaptive gradient methods scale down the gradient by the
past gradient value $\sqrt{\mathbf{s}}$, decaying the steeper
gradients more than the smoother gradients, allowing the
parameter to convergence even faster.
Adam combined the momentum and adaptive gradients
techniques.

A momentum algorithm is described as:

1. $\mathbf{m} \leftarrow \beta_1 \mathbf{m} - \eta
   \nabla_{\mathbf{\theta}}L(\mathbf{\theta})$
2. $\mathbf{\theta}\leftarrow \mathbf{\theta} + \mathbf{m}$

An adaptive gradient algorithm is described as:

1. $\mathbf{s} \leftarrow \beta_2 \mathbf{s} + (1-\beta_2)
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta}) \otimes
   \nabla_{\mathbf{\theta}}L(\mathbf{\theta})$
2. $\mathbf{\theta} \leftarrow \mathbf{\theta} - \eta
   \nabla_{\mathbf{\theta}}L(\mathbf{\theta})
   \oslash \sqrt{\mathbf{s} + \epsilon}$

The Adam algorithm is described as:

1. $\mathbf{m} \leftarrow \beta_1 \mathbf{m} - (1-\beta_1)
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta})$
2. $\mathbf{s} \leftarrow \beta_2 \mathbf{s} + (1-\beta_2)
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta}) \otimes
   \nabla_{\mathbf{\theta}} L(\mathbf{\theta})$
3. $\hat{ \mathbf{m} } \leftarrow \frac{\mathbf{m}}{1-\beta_1^t}$
4. $\hat{ \mathbf{s} } \leftarrow \frac{\mathbf{s}}{1-\beta_2^t}$
5. $\mathbf{\theta} \leftarrow \mathbf{\theta} + 
   \eta \hat{ \mathbf{m} } \oslash \sqrt{\hat{ \mathbf{s} } + \epsilon}$

Algorithms adapted from @geron_hands-machine_2017

### Dynamic learning rate with learning schedule

The learning rate $\eta$ affects the extent gradients are
updated. A too high learning rate prevents gradient descent
from converging while a too low learning rate significantly
increases the training time. Instead of using a fixed
learning rate, this paper adopts exponential scheduling
where the learning rate is updated as the training epochs
$t$ increase. We denote $\eta_0$ as the initial learning
rate, $s$ as a hyper-parameter step that decreases the
impact of the initial $s$ training epochs. As a result, the
learning rate decreases faster as the training epochs
increase.

$$
\eta(t) = \eta_0 0.1 ^{t/s}
$$

### Regularization

Regularisation refers to techniques used to prevent
over-fitting. Over-fitting occurs when the model is tuned
solely on the training data and does not generalise well in
unseen test data. For example, LASSO and Ridge modify
least square regression by including $\ell 1$ and $\ell 2$
penalties. Deep learning provides additional regularisation
techniques, including the dropout and early stopping
adopted in this paper.

#### Regularisation with dropout

Dropout is a simple yet powerful algorithm, users set a
hyper-parameter dropout rate $p$, and during training, $p$%
of the hidden units will not be included in the gradient
calculation. Intuitively, dropout forces the neural network
to train a new but dependent model during each training
epoch, avoiding relying on the same information each time.
Dropout is not used during prediction.

#### Regularisation with early stopping

Early stopping is a technique that stops model training
before the model over-fits the training data. Stopping
criteria is pre-set by the users, and for a standard neural
network, the decrease in loss function is often used as the
criteria. For example, training stops if the decrease in loss between $t$
and $t+1$ is less than $\epsilon$. However, it is
harder to decide on stopping criteria for GAN models, and
this paper uses the Sharpe ratio as the stopping criteria.
Besides preventing over-fitting, early stopping also allows
automated training as users can set higher training epochs
without terminating model training manually.

## GAN architecture {#gan_structure}

```{r child="training_GAN.Rmd"}
```

## Training Fama-French factor model

Fama-French factor model can be trained using least square
estimation. This paper minimises the mean squared error loss
function with the following minimisation with firm specific
parameters $(\beta_i, s_i, h_i, \omega_i)$ and number of
observations $T_i$,

$$
\min_{\beta_i, s_i, h_i, \omega_i} \frac{1}{T_i} \sum_{t\in T_i} \left(R^e_{t+1, i} - \alpha_i - \beta_i R^e_{mt} - s_i SMB_t - h_i HML_t - \omega_i UMD_t\right)^2.
$$

